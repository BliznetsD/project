{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import Window\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark_test\").getOrCreate()\n",
    "    #вычитывает данные из csv\n",
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"delimeter\",\",\")\\\n",
    "    .option(\"inferSchema\",True) \\\n",
    "    .load(\"stocks_price_final.csv\")\n",
    "    #Удаляем из датафрейма лишние колонки\n",
    "ddf = df.drop('sector','industry','exchange','high','low','close','volume','adjusted','marketcap')\n",
    "    #делаем нарастающий итог - используется sql решение. Далее поверх него надо уже крутить выбор последней даты\n",
    "    #Решение должно работать и на кластере, за это отвечает настройка rowsBetween, иначе будет в рамках каждого кластера считать\n",
    "windowval = (Window.partitionBy('symbol').orderBy('date')\n",
    "             .rowsBetween(Window.unboundedPreceding, 0))\n",
    "df_w_cumsum = ddf.withColumn('sum_sum', f.sum('open').over(windowval))\n",
    "    #Записываем результат в файл. По факту он записывает в отдельный партицированный файл, надо бы еще порыть\n",
    "df_w_cumsum.repartition(1).write.format(\"csv\").mode(\"overwrite\").option(\"header\",\"true\").save(\"new_test_3.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48244f177d47e8f37ab9c2fa88a9e63a8a67c15c9aad311ba03e7853f7f734cd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
